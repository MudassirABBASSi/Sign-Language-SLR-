{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11092185,
          "sourceType": "datasetVersion",
          "datasetId": 6914437
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Sign Language (SLR)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MudassirABBASSi/Sign-Language-SLR-/blob/main/Sign_Language_(SLR).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "psap2SiHNQQS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mudassirabbassi_data1122_path = kagglehub.dataset_download('mudassirabbassi/data1122')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Y04ZspHdNQQc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Annotations and List Video Files"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2025-03-22T07:08:01.499328Z",
          "iopub.execute_input": "2025-03-22T07:08:01.499647Z",
          "iopub.status.idle": "2025-03-22T07:08:03.573225Z",
          "shell.execute_reply.started": "2025-03-22T07:08:01.499624Z",
          "shell.execute_reply": "2025-03-22T07:08:03.572314Z"
        },
        "id": "aRJ39FI3NQQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "dataset_path = \"/kaggle/input/data1122/New folder/data/data\"\n",
        "annotations_path = os.path.join(dataset_path, \"annotations\")\n",
        "videos_path = os.path.join(\n",
        "    dataset_path, \"videos\")\n",
        "\n",
        "# Read annotation files\n",
        "df_train = pd.read_excel(os.path.join(annotations_path, \"train.xlsx\"))\n",
        "df_test = pd.read_excel(os.path.join(annotations_path, \"test.xlsx\"))\n",
        "df_dev = pd.read_excel(os.path.join(annotations_path, \"dev.xlsx\"))\n",
        "\n",
        "# Display sample data\n",
        "print(\"Train Annotations:\", df_train.head())\n",
        "print(\"Test Annotations:\", df_test.head())\n",
        "print(\"Dev Annotations:\", df_dev.head())\n",
        "\n",
        "# List sample videos\n",
        "print(\"Train Videos:\", os.listdir(os.path.join(videos_path, \"train\"))[:5])\n",
        "print(\"Test Videos:\", os.listdir(os.path.join(videos_path, \"test\"))[:5])\n",
        "print(\"Dev Videos:\", os.listdir(os.path.join(videos_path, \"dev\"))[:5])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:57:37.670461Z",
          "iopub.execute_input": "2025-03-22T09:57:37.670786Z",
          "iopub.status.idle": "2025-03-22T09:57:39.680217Z",
          "shell.execute_reply.started": "2025-03-22T09:57:37.670752Z",
          "shell.execute_reply": "2025-03-22T09:57:39.679376Z"
        },
        "id": "Pl_wdQxKNQQl",
        "outputId": "5d713db6-c792-420c-9b62-ba985a7ea3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train Annotations:                                          name    signer  \\\n0  train/11August_2010_Wednesday_tagesschau-1  Signer08   \n1  train/11August_2010_Wednesday_tagesschau-4  Signer08   \n2  train/11August_2010_Wednesday_tagesschau-5  Signer08   \n3  train/11August_2010_Wednesday_tagesschau-6  Signer08   \n4  train/11August_2010_Wednesday_tagesschau-7  Signer08   \n\n                                               gloss  \\\n0      JETZT WETTER MORGEN DONNERSTAG ZWOELF FEBRUAR   \n1  ORT REGEN DURCH REGEN KOENNEN UEBERSCHWEMMUNG ...   \n2  NORDWEST HEUTE NACHT TROCKEN BLEIBEN SUEDWEST ...   \n3  TAGSUEBER OFT REGEN GEWITTER KOENNEN MANCHMAL ...   \n4                       WOLKE LOCH SPEZIELL NORDWEST   \n\n                                                text  \n0  und nun die wettervorhersage für morgen donner...  \n1  mancherorts regnet es auch länger und ergiebig...  \n2  im nordwesten bleibt es heute nacht meist troc...  \n3  auch am tag gibt es verbreitet zum teil kräfti...  \n4  größere wolkenlücken finden sich vor allem im ...  \nTest Annotations:                                            name    signer  \\\n0      test/25October_2010_Monday_tagesschau-17  Signer01   \n1      test/25October_2010_Monday_tagesschau-24  Signer01   \n2  test/15December_2010_Wednesday_tagesschau-37  Signer05   \n3           test/10March_2011_Thursday_heute-58  Signer01   \n4       test/14August_2009_Friday_tagesschau-62  Signer05   \n\n                                               gloss  \\\n0  REGEN SCHNEE REGION VERSCHWINDEN NORD REGEN KO...   \n1  DONNERSTAG NORDWEST REGEN REGION SONNE WOLKE W...   \n2  KRAEFTIG AB MORGEN FRUEH MEISTENS SCHNEE SCHNE...   \n3  WOCHENENDE SONNE SAMSTAG SCHOEN TEMPERATUR BIS...   \n4  DEUTSCH LAND MORGEN HOCH DRUCK KOMMEN WOLKE AU...   \n\n                                                text  \n0  regen und schnee lassen an den alpen in der na...  \n1  am donnerstag regen in der nordhälfte in der s...  \n2  vom nordmeer zieht ein kräftiges tief heran un...  \n3  sonnig geht es auch ins wochenende samstag ein...  \n4  deutschland liegt morgen unter hochdruckeinflu...  \nDev Annotations:                                        name    signer  \\\n0  dev/11August_2010_Wednesday_tagesschau-2  Signer08   \n1  dev/11August_2010_Wednesday_tagesschau-3  Signer08   \n2  dev/11August_2010_Wednesday_tagesschau-8  Signer08   \n3   dev/25October_2010_Monday_tagesschau-22  Signer01   \n4     dev/05May_2011_Thursday_tagesschau-25  Signer08   \n\n                                               gloss  \\\n0                                  DRUCK TIEF KOMMEN   \n1  ES-BEDEUTET VIEL WOLKE UND KOENNEN REGEN GEWIT...   \n2  WIND MAESSIG SCHWACH REGION WENN GEWITTER WIND...   \n3  MITTWOCH REGEN KOENNEN NORDWEST WAHRSCHEINLICH...   \n4  JETZT WETTER WIE-AUSSEHEN MORGEN FREITAG SECHS...   \n\n                                                text  \n0  tiefer luftdruck bestimmt in den nächsten tage...  \n1  das bedeutet viele wolken und immer wieder zum...  \n2  meist weht nur ein schwacher wind aus untersch...  \n3  am mittwoch hier und da nieselregen in der nor...  \n4  und nun die wettervorhersage für morgen freita...  \nTrain Videos: ['05March_2011_Saturday_tagesschau-5450.mp4', '20July_2010_Tuesday_heute-5259.mp4', '18February_2011_Friday_tagesschau-6835.mp4', '25July_2011_Monday_heute-8229.mp4', '10August_2010_Tuesday_heute-1444.mp4']\nTest Videos: ['24September_2009_Thursday_heute-6091.mp4', '21August_2010_Saturday_tagesschau-8822.mp4', '14December_2010_Tuesday_heute-650.mp4', '05May_2010_Wednesday_tagesschau-3353.mp4', '17January_2011_Monday_tagesschau-7005.mp4']\nDev Videos: ['08January_2010_Friday_tagesschau-3984.mp4', '12July_2011_Tuesday_heute-1281.mp4', '25August_2009_Tuesday_tagesschau-7093.mp4', '06February_2011_Sunday_tagesschau-6917.mp4', '06October_2012_Saturday_tagesschau-8730.mp4']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Video Preprocessing"
      ],
      "metadata": {
        "id": "8VovaN67NQRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_rate=5):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video at a specific frame rate and saves them as images.\n",
        "\n",
        "    :param video_path: Path to the video file.\n",
        "    :param output_folder: Folder to save extracted frames.\n",
        "    :param frame_rate: Number of frames to extract per second.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_interval = max(1, fps // frame_rate)\n",
        "\n",
        "    frame_count = 0\n",
        "    saved_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"frame_{saved_count:04d}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            saved_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {saved_count} frames from {video_path}\")\n",
        "\n",
        "# Example usage\n",
        "video_file = os.path.join(videos_path, \"train\", \"05March_2011_Saturday_tagesschau-5450.mp4\")\n",
        "output_folder = \"/kaggle/working/extracted_frames/train\"\n",
        "\n",
        "extract_frames(video_file, output_folder)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:57:39.681086Z",
          "iopub.execute_input": "2025-03-22T09:57:39.68149Z",
          "iopub.status.idle": "2025-03-22T09:57:40.262688Z",
          "shell.execute_reply.started": "2025-03-22T09:57:39.681466Z",
          "shell.execute_reply": "2025-03-22T09:57:40.262025Z"
        },
        "id": "j-kNWDhKNQRe",
        "outputId": "55d6eee0-fcbc-4f13-ddd0-aa140b1707d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Extracted 14 frames from /kaggle/input/data1122/New folder/data/data/videos/train/05March_2011_Saturday_tagesschau-5450.mp4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction Using MediaPipe\n"
      ],
      "metadata": {
        "id": "-c3wYcTENQRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Initialize the holistic model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:57:40.263416Z",
          "iopub.execute_input": "2025-03-22T09:57:40.263626Z",
          "iopub.status.idle": "2025-03-22T09:58:13.399048Z",
          "shell.execute_reply.started": "2025-03-22T09:57:40.263607Z",
          "shell.execute_reply": "2025-03-22T09:58:13.398336Z"
        },
        "id": "pw_hM49TNQRi",
        "outputId": "8717c5ce-0e68-4486-b90f-99683e350063"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting mediapipe\n  Downloading mediapipe-0.10.21-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (25.1.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\nRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.5)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\nCollecting protobuf<5,>=4.25.3 (from mediapipe)\n  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting sounddevice>=0.4.4 (from mediapipe)\n  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2.4.1)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\nDownloading mediapipe-0.10.21-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\nInstalling collected packages: protobuf, sounddevice, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.6 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.21 protobuf-4.25.6 sounddevice-0.5.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Define Function for Feature Extraction\n",
        "This function processes each frame and extracts:\n",
        "\n",
        "Pose landmarks (full body)\n",
        "\n",
        "Hand landmarks (left and right hands)\n",
        "\n",
        "Face landmarks (expressions)"
      ],
      "metadata": {
        "id": "qO1np_2DNQRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keypoints(image):\n",
        "    \"\"\"\n",
        "    Extracts key points from an image using MediaPipe Holistic model.\n",
        "\n",
        "    :param image: Input image (frame from video).\n",
        "    :return: Flattened array of extracted key points.\n",
        "    \"\"\"\n",
        "    with mp_holistic.Holistic(static_image_mode=True) as holistic:\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = holistic.process(image_rgb)\n",
        "\n",
        "        # Extract key points\n",
        "        pose = results.pose_landmarks.landmark if results.pose_landmarks else []\n",
        "        face = results.face_landmarks.landmark if results.face_landmarks else []\n",
        "        lh = results.left_hand_landmarks.landmark if results.left_hand_landmarks else []\n",
        "        rh = results.right_hand_landmarks.landmark if results.right_hand_landmarks else []\n",
        "\n",
        "        # Convert to NumPy arrays\n",
        "        pose = np.array([[p.x, p.y, p.z] for p in pose]).flatten() if pose else np.zeros(33*3)\n",
        "        face = np.array([[f.x, f.y, f.z] for f in face]).flatten() if face else np.zeros(468*3)\n",
        "        lh = np.array([[l.x, l.y, l.z] for l in lh]).flatten() if lh else np.zeros(21*3)\n",
        "        rh = np.array([[r.x, r.y, r.z] for r in rh]).flatten() if rh else np.zeros(21*3)\n",
        "\n",
        "        return np.concatenate([pose, face, lh, rh])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:13.401366Z",
          "iopub.execute_input": "2025-03-22T09:58:13.40186Z",
          "iopub.status.idle": "2025-03-22T09:58:13.407935Z",
          "shell.execute_reply.started": "2025-03-22T09:58:13.401809Z",
          "shell.execute_reply": "2025-03-22T09:58:13.407142Z"
        },
        "id": "yxVJvra5NQRl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Extract Features for Each Frame\n",
        "Now, loop through all frames and extract key points."
      ],
      "metadata": {
        "id": "sGaztc68NQRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_folder = \"/kaggle/working/extracted_frames/train\"\n",
        "features = []\n",
        "\n",
        "for frame_file in sorted(os.listdir(frame_folder)):\n",
        "    frame_path = os.path.join(frame_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "\n",
        "    if frame is not None:\n",
        "        keypoints = extract_keypoints(frame)\n",
        "        features.append(keypoints)\n",
        "\n",
        "# Convert to NumPy array\n",
        "features = np.array(features)\n",
        "print(\"Feature shape:\", features.shape)  # (num_frames, feature_size)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:13.409617Z",
          "iopub.execute_input": "2025-03-22T09:58:13.40996Z",
          "iopub.status.idle": "2025-03-22T09:58:16.50576Z",
          "shell.execute_reply.started": "2025-03-22T09:58:13.409929Z",
          "shell.execute_reply": "2025-03-22T09:58:16.505087Z"
        },
        "id": "6d3tD24GNQRn",
        "outputId": "105567a3-b1df-46dd-e6d4-6ad9ea39e30a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Feature shape: (14, 1629)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data for Model Training\n",
        "\n",
        "Now, let’s move forward with preparing the dataset for training.\n",
        "We will:\n",
        "\n",
        "1️⃣ Label the extracted features based on the gloss (sign language word/phrase).\n",
        "\n",
        "2️⃣ Organize the data into training, validation, and test sets.\n",
        "\n",
        "3️⃣ Train an LSTM model for sequence classification.  \n",
        " # Load Annotations (Labels)"
      ],
      "metadata": {
        "id": "OPWjp9TSNQRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train annotations\n",
        "annotations_path = \"/kaggle/input/data1122/New folder/data/data/annotations/train.xlsx\"\n",
        "df_train = pd.read_excel(annotations_path)\n",
        "\n",
        "# Display first few rows\n",
        "print(df_train.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:16.50665Z",
          "iopub.execute_input": "2025-03-22T09:58:16.506959Z",
          "iopub.status.idle": "2025-03-22T09:58:17.428351Z",
          "shell.execute_reply.started": "2025-03-22T09:58:16.506933Z",
          "shell.execute_reply": "2025-03-22T09:58:17.427437Z"
        },
        "id": "XutI7_mQNQRp",
        "outputId": "2eec769d-33d3-475d-f769-15cce5fd82c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                         name    signer  \\\n0  train/11August_2010_Wednesday_tagesschau-1  Signer08   \n1  train/11August_2010_Wednesday_tagesschau-4  Signer08   \n2  train/11August_2010_Wednesday_tagesschau-5  Signer08   \n3  train/11August_2010_Wednesday_tagesschau-6  Signer08   \n4  train/11August_2010_Wednesday_tagesschau-7  Signer08   \n\n                                               gloss  \\\n0      JETZT WETTER MORGEN DONNERSTAG ZWOELF FEBRUAR   \n1  ORT REGEN DURCH REGEN KOENNEN UEBERSCHWEMMUNG ...   \n2  NORDWEST HEUTE NACHT TROCKEN BLEIBEN SUEDWEST ...   \n3  TAGSUEBER OFT REGEN GEWITTER KOENNEN MANCHMAL ...   \n4                       WOLKE LOCH SPEZIELL NORDWEST   \n\n                                                text  \n0  und nun die wettervorhersage für morgen donner...  \n1  mancherorts regnet es auch länger und ergiebig...  \n2  im nordwesten bleibt es heute nacht meist troc...  \n3  auch am tag gibt es verbreitet zum teil kräfti...  \n4  größere wolkenlücken finden sich vor allem im ...  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Map Features to Labels"
      ],
      "metadata": {
        "id": "qiUvmSITNQRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train[\"name\"].head(10))  # Print first 10 rows\n",
        "video_name = \"train/05March_2011_Saturday_tagesschau-5450\"  # Removed .mp4\n",
        "\n",
        "matching_rows = df_train[df_train[\"name\"].str.contains(video_name, na=False)]\n",
        "\n",
        "if not matching_rows.empty:\n",
        "    gloss_label = matching_rows[\"gloss\"].iloc[0]\n",
        "    print(\"Label for this video:\", gloss_label)\n",
        "else:\n",
        "    print(\"No matching label found for this video.\")\n",
        "matching_rows = df_train[df_train[\"name\"].str.contains(\"05March_2011_Saturday_tagesschau-5450\", na=False)]\n",
        "print(df_train[df_train[\"name\"].str.contains(\"05March\", na=False)])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:17.429358Z",
          "iopub.execute_input": "2025-03-22T09:58:17.429584Z",
          "iopub.status.idle": "2025-03-22T09:58:17.450592Z",
          "shell.execute_reply.started": "2025-03-22T09:58:17.429564Z",
          "shell.execute_reply": "2025-03-22T09:58:17.449706Z"
        },
        "id": "X3W24EXCNQRr",
        "outputId": "06fa0782-1019-486d-c7ce-9cf14b22d873"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "0     train/11August_2010_Wednesday_tagesschau-1\n1     train/11August_2010_Wednesday_tagesschau-4\n2     train/11August_2010_Wednesday_tagesschau-5\n3     train/11August_2010_Wednesday_tagesschau-6\n4     train/11August_2010_Wednesday_tagesschau-7\n5     train/11August_2010_Wednesday_tagesschau-9\n6    train/11August_2010_Wednesday_tagesschau-10\n7    train/11August_2010_Wednesday_tagesschau-11\n8    train/11August_2010_Wednesday_tagesschau-12\n9    train/11August_2010_Wednesday_tagesschau-13\nName: name, dtype: object\nLabel for this video: MITTWOCH NORDWEST KOMMEN REGEN\n                                             name    signer  \\\n4380  train/05March_2011_Saturday_tagesschau-5438  Signer05   \n4381  train/05March_2011_Saturday_tagesschau-5439  Signer05   \n4382  train/05March_2011_Saturday_tagesschau-5440  Signer05   \n4383  train/05March_2011_Saturday_tagesschau-5441  Signer05   \n4384  train/05March_2011_Saturday_tagesschau-5444  Signer05   \n4385  train/05March_2011_Saturday_tagesschau-5445  Signer05   \n4386  train/05March_2011_Saturday_tagesschau-5446  Signer05   \n4387  train/05March_2011_Saturday_tagesschau-5448  Signer05   \n4388  train/05March_2011_Saturday_tagesschau-5449  Signer05   \n4389  train/05March_2011_Saturday_tagesschau-5450  Signer05   \n4390  train/05March_2011_Saturday_tagesschau-5451  Signer05   \n\n                                                  gloss  \\\n4380  JETZT WETTER WIE-AUSSEHEN MORGEN SONNTAG SECHS...   \n4381            NORD HOCH UND IX TIEF MEHR KUEHL KOMMEN   \n4382  ABER TROCKEN HOCH DRUCK SCHNELL DANN IM-VERLAU...   \n4383  NORD HEUTE NACHT KLAR HIMMEL SUED IX BISSCHEN ...   \n4384              NORD SONNE MITTE AUCH MEHR FREUNDLICH   \n4385  MORGEN SCHWACH MAESSIG WEHEN KOENNEN FRISCH WE...   \n4386       NACHT REGION FROST BIS MINUS SIEBEN ALPEN IX   \n4387  WIE-AUSSEHEN IN-KOMMEND MONTAG SONNE TROCKEN S...   \n4388      DIENSTAG AUCH SONNE REGION BISSCHEN MEHR MILD   \n4389                     MITTWOCH NORDWEST KOMMEN REGEN   \n4390                                 SUEDOST FREUNDLICH   \n\n                                                   text  \n4380  und nun die wettervorhersage für morgen sonnta...  \n4381  zwischen dem hoch über der nordsee und dem tie...  \n4382  da sie aber auch trocken ist und zudem rasch u...  \n4383  im norden ist es heute nacht meist klar in der...  \n4384  im norden scheint verbreitet die sonne und auc...  \n4385  morgen weht ein schwacher bis mäßiger stellenw...  \n4386  in der nacht wird es überall frostig bis minus...  \n4387  die aussichten am montag sonnig und trocken im...  \n4388  auch am dienstag scheint verbreitet die sonne ...  \n4389     am mittwoch zieht von nordwesten regen heran .  \n4390     im süden und osten bleibt es noch freundlich .  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "video_name = \"05March_2011_Saturday_tagesschau-5450.mp4\"\n",
        "video_name = \"train/05March_2011_Saturday_tagesschau-5450\"  # Correct format\n",
        "\n",
        "matching_rows = df_train[df_train[\"name\"].str.contains(video_name, na=False)]\n",
        "\n",
        "if not matching_rows.empty:\n",
        "    gloss_label = matching_rows[\"gloss\"].iloc[0]\n",
        "    print(\"Label for this video:\", gloss_label)\n",
        "else:\n",
        "    print(\"No matching label found for this video.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:17.451471Z",
          "iopub.execute_input": "2025-03-22T09:58:17.451758Z",
          "iopub.status.idle": "2025-03-22T09:58:17.470997Z",
          "shell.execute_reply.started": "2025-03-22T09:58:17.45173Z",
          "shell.execute_reply": "2025-03-22T09:58:17.470122Z"
        },
        "id": "J8hR3FhiNQRs",
        "outputId": "81e458d6-db34-4c11-f953-83cb6c2fb613"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Label for this video: MITTWOCH NORDWEST KOMMEN REGEN\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan for Feature Extraction\n",
        "1️⃣ Extract hand landmarks using MediaPipe Hands\n",
        "\n",
        "2️⃣ Extract face mesh & lips using MediaPipe Face Mesh\n",
        "\n",
        "3️⃣ Extract body pose using MediaPipe Pose\n",
        "\n",
        "4️⃣ Store extracted features in a structured format (CSV/JSON/Pickle)"
      ],
      "metadata": {
        "id": "zInED-tXNQRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python mediapipe pandas numpy\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:17.471899Z",
          "iopub.execute_input": "2025-03-22T09:58:17.472147Z",
          "iopub.status.idle": "2025-03-22T09:58:20.806725Z",
          "shell.execute_reply.started": "2025-03-22T09:58:17.472126Z",
          "shell.execute_reply": "2025-03-22T09:58:20.805589Z"
        },
        "id": "bIYooucxNQRt",
        "outputId": "713452ca-0afa-4917-9b2e-8a1e878879e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.21)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (25.1.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\nRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.5)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\nRequirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.6)\nRequirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking the availability of the videos for Feature Extraction"
      ],
      "metadata": {
        "id": "hAkNPTrHNQRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "video_folder = \"/kaggle/input/data1122/New folder/data/data/videos\"\n",
        "\n",
        "if not os.path.exists(video_folder):\n",
        "    print(f\"❌ Error: Folder does not exist: {video_folder}\")\n",
        "else:\n",
        "    print(f\"✅ Folder exists: {video_folder}\")\n",
        "    print(\"📂 Listing files in the folder:\")\n",
        "\n",
        "    files = os.listdir(video_folder)\n",
        "    for file in files:\n",
        "        print(f\"- {file} (Type: {'Folder' if os.path.isdir(os.path.join(video_folder, file)) else 'File'})\")\n",
        "\n",
        "import os\n",
        "\n",
        "video_folder = \"/kaggle/input/data1122/New folder/data/data/videos\"\n",
        "\n",
        "# Search for videos inside all subfolders\n",
        "video_files = []\n",
        "for root, dirs, files in os.walk(video_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(\".mp4\"):\n",
        "            video_files.append(os.path.join(root, file))  # Get full path\n",
        "\n",
        "print(f\"📂 Found {len(video_files)} videos.\")\n",
        "if video_files:\n",
        "    for video in video_files[:5]:  # Print first 5 videos for verification\n",
        "        print(f\"✅ {video}\")\n",
        "else:\n",
        "    print(\"❌ No video files found! Check your dataset.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:20.808002Z",
          "iopub.execute_input": "2025-03-22T09:58:20.8083Z",
          "iopub.status.idle": "2025-03-22T09:58:25.632915Z",
          "shell.execute_reply.started": "2025-03-22T09:58:20.80826Z",
          "shell.execute_reply": "2025-03-22T09:58:25.632183Z"
        },
        "id": "K7FfAZ5MNQRt",
        "outputId": "ffa95c6b-e613-4146-e2ae-3d07cd70ac30"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Folder exists: /kaggle/input/data1122/New folder/data/data/videos\n📂 Listing files in the folder:\n- test (Type: Folder)\n- train (Type: Folder)\n- dev (Type: Folder)\n📂 Found 8257 videos.\n✅ /kaggle/input/data1122/New folder/data/data/videos/test/24September_2009_Thursday_heute-6091.mp4\n✅ /kaggle/input/data1122/New folder/data/data/videos/test/21August_2010_Saturday_tagesschau-8822.mp4\n✅ /kaggle/input/data1122/New folder/data/data/videos/test/14December_2010_Tuesday_heute-650.mp4\n✅ /kaggle/input/data1122/New folder/data/data/videos/test/05May_2010_Wednesday_tagesschau-3353.mp4\n✅ /kaggle/input/data1122/New folder/data/data/videos/test/17January_2011_Monday_tagesschau-7005.mp4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Initialize MediaPipe solutions\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Load MediaPipe models\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
        "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Function to extract keypoints\n",
        "def extract_keypoints(results_hands, results_face, results_pose):\n",
        "    keypoints = []\n",
        "\n",
        "    # Extract Hand Landmarks (Left & Right)\n",
        "    for hand in results_hands.multi_hand_landmarks if results_hands.multi_hand_landmarks else []:\n",
        "        for landmark in hand.landmark:\n",
        "            keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "    keypoints.extend([0] * (21 * 3 * 2 - len(keypoints)))  # Pad if missing\n",
        "\n",
        "    # Extract Face Mesh Landmarks (468 points)\n",
        "    if results_face.multi_face_landmarks:\n",
        "        for landmark in results_face.multi_face_landmarks[0].landmark:\n",
        "            keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "    else:\n",
        "        keypoints.extend([0] * (468 * 3))  # Pad if missing\n",
        "\n",
        "    # Extract Pose Landmarks (33 points)\n",
        "    if results_pose.pose_landmarks:\n",
        "        for landmark in results_pose.pose_landmarks.landmark:\n",
        "            keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "    else:\n",
        "        keypoints.extend([0] * (33 * 4))  # Pad if missing\n",
        "\n",
        "    return keypoints\n",
        "\n",
        "# Process all videos in the dataset\n",
        "video_folder = \"/kaggle/input/data1122/New folder/data/data/videos\"\n",
        "output_csv = \"extracted_features.csv\"\n",
        "data = []\n",
        "\n",
        "# Look inside all subfolders\n",
        "video_files = []\n",
        "for root, dirs, files in os.walk(video_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(\".mp4\"):\n",
        "            video_files.append(os.path.join(root, file))  # Get full path\n",
        "\n",
        "print(f\"📂 Found {len(video_files)} videos.\")\n",
        "\n",
        "if not video_files:\n",
        "    print(\"❌ No video files found. Check the dataset path.\")\n",
        "else:\n",
        "    for video_path in video_files:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        video_name = os.path.basename(video_path)\n",
        "\n",
        "        frame_id = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Convert to RGB\n",
        "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Process frame with MediaPipe models\n",
        "            results_hands = hands.process(rgb_frame)\n",
        "            results_face = face_mesh.process(rgb_frame)\n",
        "            results_pose = pose.process(rgb_frame)\n",
        "\n",
        "            # Extract keypoints\n",
        "            keypoints = extract_keypoints(results_hands, results_face, results_pose)\n",
        "\n",
        "            # Store data (video_name, frame_id, features)\n",
        "            data.append([video_name, frame_id] + keypoints)\n",
        "            frame_id += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Save extracted features to CSV\n",
        "if data:\n",
        "    columns = [\"video_name\", \"frame_id\"] + [f\"feature_{i}\" for i in range(len(data[0]) - 2)]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Feature extraction completed! Data saved to {output_csv}\")\n",
        "else:\n",
        "    print(\"❌ No features extracted. Check video processing.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:58:25.633776Z",
          "iopub.execute_input": "2025-03-22T09:58:25.634072Z",
          "execution_failed": "2025-03-22T10:28:42.311Z"
        },
        "id": "Fuay3DaDNQRu",
        "outputId": "a7de8a2c-7d6d-4ee7-9ffe-f73c169685bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "📂 Found 8257 videos.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction code"
      ],
      "metadata": {
        "id": "4vT_eKdbNQRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# ✅ Enable OpenCV CUDA if available\n",
        "if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
        "    print(\"✅ OpenCV CUDA is enabled!\")\n",
        "    cv2.setUseOptimized(True)\n",
        "    cv2.cuda.setDevice(0)\n",
        "else:\n",
        "    print(\"⚠️ OpenCV CUDA not available. Using CPU.\")\n",
        "\n",
        "# ✅ Initialize MediaPipe solutions\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# ✅ Function to extract keypoints (hand, face, pose)\n",
        "def extract_keypoints(frame):\n",
        "    global hands, face_mesh, pose  # Use global models to reduce reloading time\n",
        "\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results_hands = hands.process(rgb_frame)\n",
        "    results_face = face_mesh.process(rgb_frame)\n",
        "    results_pose = pose.process(rgb_frame)\n",
        "\n",
        "    keypoints = []\n",
        "\n",
        "    # Hand Landmarks (21 x 3 per hand)\n",
        "    if results_hands.multi_hand_landmarks:\n",
        "        for hand in results_hands.multi_hand_landmarks:\n",
        "            for landmark in hand.landmark:\n",
        "                keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "    keypoints.extend([0] * (21 * 3 * 2 - len(keypoints)))  # Pad missing values\n",
        "\n",
        "    # Face Mesh Landmarks (468 x 3)\n",
        "    if results_face.multi_face_landmarks:\n",
        "        for landmark in results_face.multi_face_landmarks[0].landmark:\n",
        "            keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "    else:\n",
        "        keypoints.extend([0] * (468 * 3))\n",
        "\n",
        "    # Pose Landmarks (33 x 4)\n",
        "    if results_pose.pose_landmarks:\n",
        "        for landmark in results_pose.pose_landmarks.landmark:\n",
        "            keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "    else:\n",
        "        keypoints.extend([0] * (33 * 4))\n",
        "\n",
        "    return keypoints\n",
        "\n",
        "# ✅ Process a single video\n",
        "def process_video(video_path):\n",
        "    video_name = os.path.basename(video_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    frame_data = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        keypoints = extract_keypoints(frame)\n",
        "        frame_data.append([video_name, frame_count] + keypoints)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frame_data\n",
        "\n",
        "# ✅ Get all video paths\n",
        "video_root_folder = \"/kaggle/input/data1122/New folder/data/data/videos\"\n",
        "video_files = []\n",
        "\n",
        "for subfolder in [\"train\", \"test\", \"dev\"]:\n",
        "    subfolder_path = os.path.join(video_root_folder, subfolder)\n",
        "    for file in os.listdir(subfolder_path):\n",
        "        if file.endswith(\".mp4\"):\n",
        "            video_files.append(os.path.join(subfolder_path, file))\n",
        "\n",
        "print(f\"📂 Found {len(video_files)} videos.\")\n",
        "\n",
        "# ✅ Process videos in parallel using multiple CPU cores\n",
        "num_workers = max(1, cpu_count() - 2)  # Keep 2 cores free for Kaggle's system\n",
        "with Pool(num_workers) as pool:\n",
        "    all_data = list(tqdm(pool.imap(process_video, video_files), total=len(video_files), desc=\"Extracting Features\"))\n",
        "\n",
        "# ✅ Flatten the extracted data\n",
        "data = [item for sublist in all_data for item in sublist]\n",
        "\n",
        "# ✅ Save extracted features to CSV\n",
        "if data:\n",
        "    columns = [\"video_name\", \"frame\"] + [f\"feature_{i}\" for i in range(len(data[0]) - 2)]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    output_csv = \"extracted_features.csv\"\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Feature extraction completed! Data saved to {output_csv}\")\n",
        "else:\n",
        "    print(\"❌ No features extracted! Check the video processing.\")\n",
        "\n",
        "\n",
        "# import os\n",
        "# import cv2\n",
        "# import mediapipe as mp\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Initialize MediaPipe solutions\n",
        "# mp_hands = mp.solutions.hands\n",
        "# mp_face_mesh = mp.solutions.face_mesh\n",
        "# mp_pose = mp.solutions.pose\n",
        "\n",
        "# hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
        "# face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "# pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# # Function to extract keypoints\n",
        "# def extract_keypoints(results_hands, results_face, results_pose):\n",
        "#     keypoints = []\n",
        "\n",
        "#     # Hand Landmarks\n",
        "#     if results_hands.multi_hand_landmarks:\n",
        "#         for hand in results_hands.multi_hand_landmarks:\n",
        "#             for landmark in hand.landmark:\n",
        "#                 keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "#     keypoints.extend([0] * (21 * 3 * 2 - len(keypoints)))  # Pad if missing\n",
        "\n",
        "#     # Face Mesh Landmarks (468 points)\n",
        "#     if results_face.multi_face_landmarks:\n",
        "#         for landmark in results_face.multi_face_landmarks[0].landmark:\n",
        "#             keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
        "#     else:\n",
        "#         keypoints.extend([0] * (468 * 3))\n",
        "\n",
        "#     # Pose Landmarks (33 points)\n",
        "#     if results_pose.pose_landmarks:\n",
        "#         for landmark in results_pose.pose_landmarks.landmark:\n",
        "#             keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "#     else:\n",
        "#         keypoints.extend([0] * (33 * 4))\n",
        "\n",
        "#     return keypoints\n",
        "\n",
        "# # Process all videos in the dataset\n",
        "# video_root_folder = \"/kaggle/input/data1122/New folder/data/data/videos\"\n",
        "# output_csv = \"extracted_features.csv\"\n",
        "# data = []\n",
        "\n",
        "# # Get all video paths from subfolders\n",
        "# video_files = []\n",
        "# for subfolder in [\"train\", \"test\", \"dev\"]:\n",
        "#     subfolder_path = os.path.join(video_root_folder, subfolder)\n",
        "#     for file in os.listdir(subfolder_path):\n",
        "#         if file.endswith(\".mp4\"):\n",
        "#             video_files.append(os.path.join(subfolder_path, file))\n",
        "\n",
        "# print(f\"📂 Found {len(video_files)} videos.\")\n",
        "\n",
        "# # Process videos\n",
        "# for video_path in tqdm(video_files, desc=\"Extracting Features\"):\n",
        "#     video_name = os.path.basename(video_path)\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#     frame_count = 0\n",
        "#     while cap.isOpened():\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret:\n",
        "#             break\n",
        "\n",
        "#         # Convert to RGB\n",
        "#         rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#         # Process frame with MediaPipe models\n",
        "#         results_hands = hands.process(rgb_frame)\n",
        "#         results_face = face_mesh.process(rgb_frame)\n",
        "#         results_pose = pose.process(rgb_frame)\n",
        "\n",
        "#         # Extract keypoints\n",
        "#         keypoints = extract_keypoints(results_hands, results_face, results_pose)\n",
        "\n",
        "#         # Store data\n",
        "#         data.append([video_name, frame_count] + keypoints)\n",
        "#         frame_count += 1\n",
        "\n",
        "#     cap.release()\n",
        "\n",
        "# # Save extracted features to CSV\n",
        "# if data:\n",
        "#     columns = [\"video_name\", \"frame\"] + [f\"feature_{i}\" for i in range(len(data[0]) - 2)]\n",
        "#     df = pd.DataFrame(data, columns=columns)\n",
        "#     df.to_csv(output_csv, index=False)\n",
        "#     print(f\"✅ Feature extraction completed! Data saved to {output_csv}\")\n",
        "# else:\n",
        "#     print(\"❌ No features extracted! Check the video processing.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T10:35:48.164077Z",
          "iopub.execute_input": "2025-03-22T10:35:48.164416Z",
          "iopub.status.idle": "2025-03-22T10:35:48.619026Z",
          "shell.execute_reply.started": "2025-03-22T10:35:48.164392Z",
          "shell.execute_reply": "2025-03-22T10:35:48.617908Z"
        },
        "id": "ogyU8z1sNQRx",
        "outputId": "37e381b9-afb5-4400-cdc1-170f0a82faf8"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8179f095f4c4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapipe'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking the csv file of Feature"
      ],
      "metadata": {
        "id": "GnvqP--9NQR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/working/extracted_frames/train\")\n",
        "print(df.head())  # Check first few rows\n",
        "print(df.shape)  # Ensure all frames are captured\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T10:35:10.625034Z",
          "iopub.execute_input": "2025-03-22T10:35:10.625239Z",
          "iopub.status.idle": "2025-03-22T10:35:11.460112Z",
          "shell.execute_reply.started": "2025-03-22T10:35:10.625199Z",
          "shell.execute_reply": "2025-03-22T10:35:11.458717Z"
        },
        "id": "Jr-RYnMINQR1",
        "outputId": "b61352f6-8e73-4c8e-ff3a-5269c84cf71d"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d14f6255510>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/extracted_frames/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Check first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure all frames are captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/extracted_frames/train'"
          ],
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/working/extracted_frames/train'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Features and Labels"
      ],
      "metadata": {
        "id": "W7uxaruINQR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save as a dictionary\n",
        "data = {\n",
        "    \"features\": features,\n",
        "    \"label\": gloss_label\n",
        "}\n",
        "\n",
        "# Save to disk\n",
        "with open(\"/kaggle/working/sign_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "print(\"Features saved successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-22T10:28:42.313Z"
        },
        "id": "O0IPemkANQR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/kaggle/working/sign_data.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "print(type(data))  # Check the type\n",
        "print(data)  # Inspect the content (if not too large)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-22T10:28:42.313Z"
        },
        "id": "Qi8JAkSpNQR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_3wKbjY5NQR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1_ORAKlCNQR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "eLw4btgLNQR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "6DrvnRT8NQR4"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}